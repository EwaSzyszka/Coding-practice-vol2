{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import struct\n",
    "from matplotlib import pyplot\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime as dt\n",
    "import sklearn\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "#fetch original mnist dataset\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, pipeline\n",
    "from sklearn.kernel_approximation import (RBFSampler, Nystroem)\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_MNIST(dataset = \"training\", path = \".\", digits=[]):\n",
    "    \"\"\"\n",
    "    Python function for importing the MNIST data set.  It returns two Numpy array\n",
    "    one with flattened feature vectors and one with the label of the digit.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset is \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset is \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "        \n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "    \n",
    "    get_img = lambda idx: (lbl[idx], img[idx])\n",
    "\n",
    "    data = []\n",
    "    for i in range(len(lbl)):\n",
    "        data.append(get_img(i))\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for digit, data in filter(lambda x: x[0] in digits, data):\n",
    "        X.append(data.flatten())\n",
    "        y.append(digit)\n",
    "        \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I chose two numbers 1 and 9 \n",
    "two_numbers = [1, 9]\n",
    "\n",
    "#X_train is data and y_train are the labels for training data\n",
    "X_train, y_train  =load_MNIST(dataset = \"training\", path = \".\", digits=two_numbers)\n",
    "\n",
    "#X_test is data and y_test are the labels for test data\n",
    "X_test, y_test  = load_MNIST(dataset = \"testing\", path = \".\", digits=two_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIgAAAD8CAYAAACsCeyFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1189e7c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting some images\n",
    "%matplotlib inline\n",
    "fig = pyplot.figure()\n",
    "ax = fig.add_subplot(2,1,1)\n",
    "imgplot = ax.imshow(X_train[1].reshape((28, 28)))\n",
    "pyplot.axis('off')\n",
    "\n",
    "ax2=  fig.add_subplot(2,1,2)\n",
    "imgplot = ax2.imshow(X_train[0].reshape((28, 28)))\n",
    "pyplot.axis('off')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVC using linear kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kernel_svm = svm.SVC(gamma=.2) #rbf used by default\n",
    "linear_svm = svm.LinearSVC()\n",
    "\n",
    "# create pipeline from kernel approximation and linear svm\n",
    "\n",
    "feature_map_fourier = RBFSampler(gamma=.2, random_state=1)\n",
    "feature_map_nystroem = Nystroem(gamma=.2, random_state=1)\n",
    "\n",
    "fourier_approx_svm = pipeline.Pipeline([(\"feature_map\", feature_map_fourier),\n",
    "                                        (\"svm\", svm.LinearSVC())])\n",
    "\n",
    "nystroem_approx_svm = pipeline.Pipeline([(\"feature_map\", feature_map_nystroem),\n",
    "                                        (\"svm\", svm.LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start linear svm learning at 2018-10-28 13:22:43.877883\n",
      "End linear svm learning at 2018-10-28 13:22:44.078806\n",
      "Elapsed learning 0:00:00.200923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "linear_svm_start_time = dt.datetime.now()\n",
    "print 'Start linear svm learning at {}'.format(str(linear_svm_start_time))\n",
    "linear_svm.fit(X_train, y_train)\n",
    "linear_svm_end_time = dt.datetime.now()\n",
    "elapsed_time = linear_svm_end_time - linear_svm_start_time\n",
    "print 'End linear svm learning at {}'.format(str(linear_svm_end_time))\n",
    "print 'Elapsed learning {}'.format(str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 9 ... 1 9 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(C=200,gamma=0.01,kernel='linear',cache_size=8000,probability=False)\n",
    "#classifier = svm.SVC()\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Now predict the value of the digit on the second half:\n",
    "#expected = label_test\n",
    "predicted = classifier.predict(X_test)\n",
    "\n",
    "#print(expected)\n",
    "df=pd.DataFrame(predicted)\n",
    "df.index+=1\n",
    "df.index.name='ImageId'\n",
    "df.columns=['Label']\n",
    "df.to_csv('results.csv',header=True)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#error rates on the testing dataset for linear kernel\n",
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVC using rbf kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start kernel svm learning at 2018-10-28 13:37:06.796911\n",
      "End kernel svm learning at 2018-10-28 13:42:08.961942\n",
      "Elapsed learning 0:05:02.165031\n",
      "Prediction takes 0:00:19.727747\n"
     ]
    }
   ],
   "source": [
    "kernel_svm_start_time = dt.datetime.now()\n",
    "print 'Start kernel svm learning at {}'.format(str(kernel_svm_start_time))\n",
    "kernel_svm.fit(X_train, y_train)\n",
    "kernel_svm_end_time = dt.datetime.now()\n",
    "elapsed_time = kernel_svm_end_time - kernel_svm_start_time\n",
    "print 'End kernel svm learning at {}'.format(str(kernel_svm_end_time))\n",
    "print 'Elapsed learning {}'.format(str(elapsed_time))\n",
    "\n",
    "kernel_svm_start_time = dt.datetime.now()\n",
    "kernel_svm_score = kernel_svm.score(X_test, y_test)\n",
    "elapsed_time = dt.datetime.now() - kernel_svm_start_time\n",
    "print 'Prediction takes {}'.format(str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(C=200,kernel='rbf',gamma=0.01,cache_size=8000,probability=False)\n",
    "#classifier = svm.SVC()\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Now predict the value of the digit on the second half:\n",
    "#expected = label_test\n",
    "predicted = classifier.predict(X_test)\n",
    "\n",
    "#print(expected)\n",
    "df=pd.DataFrame(predicted)\n",
    "df.index+=1\n",
    "df.index.name='ImageId'\n",
    "df.columns=['Label']\n",
    "df.to_csv('results.csv',header=True)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#error rates on the testing dataset for rbf kernel\n",
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVC using poly kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start kernel svm learning at 2018-10-28 13:54:03.913777\n",
      "End kernel svm learning at 2018-10-28 13:54:06.842008\n",
      "Elapsed learning 0:00:02.928231\n",
      "Prediction takes 0:00:00.453233\n"
     ]
    }
   ],
   "source": [
    "kernelpoly_svm = svm.SVC(kernel='poly', gamma = 'auto')\n",
    "\n",
    "kernelpoly_svm_start_time = dt.datetime.now()\n",
    "print 'Start kernel svm learning at {}'.format(str(kernelpoly_svm_start_time))\n",
    "kernelpoly_svm.fit(X_train, y_train)\n",
    "kernelpoly_svm_end_time = dt.datetime.now()\n",
    "elapsed_time = kernelpoly_svm_end_time - kernelpoly_svm_start_time\n",
    "print 'End kernel svm learning at {}'.format(str(kernelpoly_svm_end_time))\n",
    "print 'Elapsed learning {}'.format(str(elapsed_time))\n",
    "\n",
    "kernelpoly_svm_start_time = dt.datetime.now()\n",
    "kernelpoly_svm_score = kernelpoly_svm.score(X_test, y_test)\n",
    "elapsed_time = dt.datetime.now() - kernelpoly_svm_start_time\n",
    "print 'Prediction takes {}'.format(str(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 9 ... 1 9 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(C=200,kernel='poly',gamma=0.01,cache_size=8000,probability=False)\n",
    "#classifier = svm.SVC()\n",
    "\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Now predict the value of the digit on the second half:\n",
    "#expected = label_test\n",
    "predicted = classifier.predict(X_test)\n",
    "\n",
    "#print(expected)\n",
    "df=pd.DataFrame(predicted)\n",
    "df.index+=1\n",
    "df.index.name='ImageId'\n",
    "df.columns=['Label']\n",
    "df.to_csv('results.csv',header=True)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9967350746268657"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#error rates on the testing dataset for poly kernel\n",
    "classifier.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [anaconda]",
   "language": "python",
   "name": "Python [anaconda]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
